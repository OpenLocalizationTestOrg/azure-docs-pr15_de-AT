<properties
   pageTitle="Skalierbar Checkliste | Microsoft Azure"
   description="Prüfliste Anleitung für Design sorgen für die automatische Skalierung Azure skalierbar."
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="christb"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="07/13/2016"
   ms.author="masashin"/>

# <a name="scalability-checklist"></a>Skalierbar-Checkliste

[AZURE.INCLUDE [pnp-header](../includes/guidance-pnp-header-include.md)]

## <a name="service-design"></a>Entwurf
- **Partition der Arbeitslast**. Entwerfen Sie Teile des Prozesses zu diskreten und zerlegbar. Minimieren Sie die Größe der einzelnen Teile beim die üblichen Regeln für die Trennung von Bedenken und dem Prinzip der einzigen Verantwortung. Dadurch können Komponenten verteilt werden, die jeder Compute-Gerät (z. B. eine Rolle oder Datenbank-Server) maximiert. Es erleichtert auch die Anwendung skalieren, indem Sie Instanzen der Ressourcen hinzufügen. Weitere Informationen finden Sie unter [Partitionierung Anleitung zu berechnen](https://msdn.microsoft.com/library/dn589773.aspx).
- **Entwurf für die Skalierung**. Ist die Anwendung auf Variablen durch erhöhen und verringern die Anzahl der Instanzen von Rollen zu Warteschlangen und andere Dienste sie verwenden. Die Anwendung muss jedoch dabei beachten entwickelt. Die Anwendung und die verwendeten Dienste muss z. B. statusfreie Anfragen Instanz weitergeleitet werden sollen. Dies verhindert auch das Hinzufügen oder Entfernen von bestimmten Instanzen Benutzer beeinträchtigt. Ebenfalls muss Konfiguration oder automatische Erkennung von Instanzen implementiert hinzugefügt und entfernt, damit Code in der Anwendung die erforderlichen routing möglich. Beispielsweise können eine Anwendung eine Reihe von Warteschlangen in einem Roundrobin-Ansatz zum Weiterleiten von Anfragen an Hintergrunddienste Workerthreads ausgeführt. Die Anwendung muss erkennen ändert die Anzahl der Warteschlangen zur erfolgreichen-Anfragen und Lastausgleich für die Anwendung.
- **Wie eine Einheit**. Zusätzliche Ressourcen für Wachstum einplanen. Kennen Sie für jede Ressource die obere Grenzen Skalierung und mit der Sharding oder sich diese Grenzen überschreiten. Bestimmen Sie die Maßeinheiten des Systems in klar definierten Gruppen von Ressourcen. Dadurch Anwendung Scale-Out-Operationen einfacher und weniger anfällig für negativ auf die Anwendung über Beschränkungen durch mangelnde Ressourcen Teil des gesamten Systems. Beispiel: Hinzufügen von X Anzahl der Web-und Workerrollen erfordern y Anzahl zusätzliche Warteschlangen und Z Anzahl Speicherkonten mit der zusätzlichen Arbeitslast durch die Rollen erstellt. Damit eine Skalierungseinheit x gehören Web-und Workerrollen _y_ Warteschlangen und _Z_ Speicherkonten. Entwerfen Sie die Anwendung so, dass es problemlos skaliert wird durch eine oder mehrere Maßeinheiten hinzufügen.
- **Clientzugehörigkeit vermeiden**. Sichergestellt, dass die Anwendung keine Affinität erforderlich. Anfragen können daher Instanz weitergeleitet, und die Anzahl der Instanzen ist irrelevant. Dadurch wird verhindert, den Aufwand für das Speichern, abrufen und Verwalten von Statusinformationen für jeden Benutzer.
- **Automatische Skalierung Plattformfeatures nutzen**. Wo Hosting-Plattform unterstützt eine Skalierung, wie Azure skalieren, benutzerdefinierte oder Drittanbieter-Mechanismen bevorzugen, sofern der integrierte Mechanismus Ihre Bedürfnisse erfüllen kann. Fügen Sie reaktive Skalierung Regeln hinzu, gegebenenfalls mit unerwartete Nachfrage zu verwenden Sie geplante Skalierung Regeln möglich Ressourcen sind unverzüglich Start verfügbar. Die automatische Skalierung Operationen können in die Dienst-API Skalierung anpassen und benutzerdefinierte Leistungsindikatoren Regeln hinzufügen. Weitere Informationen finden Sie unter [Automatische Skalierung Anleitung](best-practices-auto-scaling.md).
- **Entlastung der CPU/IO-Aufgaben als Hintergrundaufgaben**. Wenn eine Anforderung an einen Dienst lange dauern oder Ressourcen aufnehmen soll, Entlastung der Verarbeitung dieser Anforderung einen separaten Vorgang. Verwenden Sie diese Aufgaben ausführen Worker-Rollen oder Hintergrundjobs (je nach Host-Plattform). Diese Strategie ermöglicht den Dienst weitere Anfragen und Reaktionsfähigkeit.  Weitere Informationen finden Sie unter [Hintergrund Aufträge Anleitung](best-practices-background-jobs.md).
- **Verteilen der Arbeitslast für Hintergrundaufgaben**. Wo gibt es viele Hintergrundaufgaben oder Aufgaben erfordern beträchtliche Zeit oder Ressourcen verteilt die Arbeit mehrere Compute-Einheiten (oder Workerthreads Hintergrundjobs). Eine mögliche Lösung finden Sie unter [Konkurrierenden Verbraucher Muster](https://msdn.microsoft.com/library/dn568101.aspx).
- **Hin prüfen einer _shared-Nothing-_ Architektur**. Shared-Nothing-Architektur verwendet unabhängige, eigenständiger Knoten, die keine zentrale Konflikte (z. B. gemeinsame Dienste oder Speicher). Theoretisch kann ein solches beinahe unbegrenztes Skalieren. Zwar vollständig freigegeben-nichts-Ansatz in der Regel nicht für die meisten, kann es besser skalierbar entwerfen ermöglichen. Beispielsweise sind serverseitigen Sitzungszustand vermeiden, Clientzugehörigkeit und Datenpartitionierung Beispiele auf eine shared-Nothing-Architektur.

## <a name="data-management"></a>Datenmanagement

- **Partitionieren von Daten**. Aufteilen der Daten über mehrere Datenbanken und Datenbankserver oder Entwurf Anwendungsdienste Datenspeicher verwenden, die die Partitionierung transparent geben (Beispiele Azure SQL elastische Datenbank und Azure Table Storage). Dieser Ansatz hilft Maximierung der Performance und Skalierung vereinfacht. Es gibt verschiedene Techniken wie horizontale, vertikale Partitionierung und funktionsfähig. Können Sie eine Kombination dieser maximalen Nutzen aus erhöhte Leistung einfacher Skalierbarkeit flexiblere, bessere Verfügbarkeit und halten sie den Typ des Speichers auf die Daten übereinstimmen. Außerdem verwenden Sie verschiedene Datenspeicher für verschiedene Datentypen, wählen die Grundlage, wie sie für den bestimmten Daten optimiert werden. Dies sind u. a. folgende Tabellenspeicher, einer Datenbank oder einem Spalte-Familie Datenspeicher, oder als eine relationale Datenbank. Weitere Informationen finden Sie unter [partitioning Guidance Daten](best-practices-data-partitioning.md).
- **Entwurf für eventual Consistency**. Eventual Consistency verbessert Skalierbarkeit vergrößert oder verkleinert die Zeit für eine Synchronisation in mehreren speichern partitionierte Daten. Die Kosten sind, dass Daten nicht immer konsistent es lesen und einige schreiben Operationen Konflikte verursachen. Eventual Consistency ist ideal für Situationen, in denen dieselben Daten oft gelesen aber selten geschrieben. Weitere Informationen finden Sie unter [Daten Konsistenz Primer](https://msdn.microsoft.com/library/dn589800.aspx).
- **Verringern Sie ausführliche Interaktionen zwischen Komponenten und Dienste**. Entwerfen von Interaktionen mit eine Anwendung mehrere Aufrufe an einen Dienst muss zu vermeiden (jeweils gibt eine kleine Datenmenge), anstatt ein einzelner Aufruf, die alle Daten zurückgeben kann. Gegebenenfalls kombinieren Sie mehrere verwandte Vorgänge in einer Anforderung wird der Aufruf einem Dienst oder einer Komponente mit deutlichen Latenz. Dies erleichtert das Überwachen der Leistung und optimieren komplexer. Beispielsweise in Datenbanken verwenden Sie gespeicherte Prozeduren, um komplexe Logik zu kapseln, und reduzieren Sie die Anzahl der Roundtrips und Ressourcensperre.
- **Warteschlangen Ebene Last für hohe Geschwindigkeit Daten schreibt**. Spannungsspitzen Nachfrage für einen Dienst können diesen Dienst überlastet und steigenden Fehler verursachen. Um dies zu verhindern, sollten Sie in der [Queue-basierten Kapazitätsabgleich Muster](https://msdn.microsoft.com/library/dn589783.aspx)implementieren. Verwenden Sie eine Warteschlange fungiert als Puffer zwischen einem Task und Dienst aufgerufen. Dies kann gelegentlich Lasten auszugleichen, die andernfalls Fehlschlagen des Dienstes oder die Aufgabe zu verursachen.
- **Minimieren Sie die Last auf den Datenspeicher**. Der Datenspeicher ist häufig Leistungsengpass teure Ressource und nicht einfach skalieren. Möglichst Logik (z. B. das Verarbeiten von XML-Dokumenten oder JSON-Objekte) aus dem Datenspeicher entfernen und in der Anwendung verarbeiten. Z. B. anstatt XML in der Datenbank (außer als undurchsichtige Zeichenfolge für Speicher), serialisieren oder Deserialisieren von XML in der Anwendungsschicht und in einem Formular auf den Datenspeicher übergeben. Es ist normalerweise viel einfacher, die Anwendung als Datenspeicher skalieren, damit Sie versuchen sollten so viele rechenintensive Verarbeitung innerhalb der Anwendung.
- **Minimieren der Datenmenge abgerufen**. Rufen Sie nur die Daten durch Angeben von Spalten und Kriterien zum Auswählen von Zeilen erforderlich. Nutzen Sie Wert die Parameter und die Isolationsstufe. Mit Mechanismen wie Entitäts-Tags zu unnötigen Daten abrufen.
- **Aggressiv Zwischenspeichern**. Verwenden Sie nach Möglichkeit reduzieren Ressourcen und Diensten, die generieren oder Daten, Zwischenspeichern. Zwischenspeichern in der Regel eignet sich für Daten relativ statisch oder erfordert beträchtliche Verarbeitung zu. Zwischenspeichern sollte auf allen Ebenen gegebenenfalls in jeder Ebene der Anwendung, einschließlich Data Access und Benutzer-Schnittstelle auftreten. Weitere Informationen finden Sie im [Leitfaden Zwischenspeichern](best-practices-caching.md).
- **Behandeln von Datenzuwachs und Aufbewahrung**. Eine Anwendung gespeicherte Datenmenge wächst mit der Zeit. Dieses Wachstum erhöht Speicherkosten und Latenz beim Zugriff auf die Daten – die Anwendungsdurchsatz und Leistung auswirkt. Es möglicherweise regelmäßig archivieren alter Daten nicht mehr zugegriffen wird oder Daten, auf die selten zugegriffen werden in langfristige Speicherung ist kostengünstiger, selbst wenn Access-Wartezeit liegt.
- **Optimieren Transfer Datenobjekte (DTOs) mit einem effizienten binären Format**. DTOs sind oft zwischen den Ebenen einer Anwendung übergeben. Minimierung der Größe reduzieren die Belastung für Ressourcen und Netzwerk. Saldo, sparen mit den Aufwand für das Konvertieren der Daten in das erforderliche Format an jedem Standort, wo sie verwendet wird. Ein Format, das die maximale Interoperabilität ermöglicht einfache Wiederverwendung einer Komponente fest.
- **Cache legen**. Entwerfen und Konfigurieren der Anwendung Ausgabecaching oder fragment caching zu Verarbeitungslast zu minimieren.
- **Das clientseitige Zwischenspeichern aktivieren**. ASP.NET-Webanwendungen sollen Cache-Einstellungen für den Inhalt, die zwischengespeichert werden können. Dies ist normalerweise standardmäßig deaktiviert. Konfigurieren der entsprechenden Cache Control-Header zum Zwischenspeichern von Inhalten auf Proxyservern und Clients liefern.
- **Mit Azure BLOB-Speicher und Azure Content Delivery Network, Belastung der Anwendung reduzieren**. Sollten Sie statische oder relativ statische öffentliche Inhalte wie Bilder, Ressourcen, Skripts und Stylesheets im BLOB-Speicher speichern. Dieser Ansatz befreit Anwendung die Last dieser Inhalt für jede Anforderung dynamisch generiert. Darüber hinaus verwenden Sie Content Delivery Network diesen Inhalt zwischenspeichern und Clients bereitzustellen. Mit Content Delivery Network verbessert Leistung auf dem Client, da der Inhalt von geografisch am nächsten Datencenter geliefert wird, die einen Netzwerk für die Inhaltsübermittlung Cache enthält. Weitere Informationen finden Sie unter [Content Delivery Network Anleitung](best-practices-cdn.md).
- **Optimieren und Abstimmung SQL-Abfragen und Indizes**. Einige T-SQL-Anweisungen oder Konstrukte möglicherweise auf die Leistung auswirken, die Optimierung des Codes in einer gespeicherten Prozedur reduziert werden kann. Vermeiden Sie z. B. **Varchar** **Datetime** -Typen umwandeln, bevor eine **Datetime** Literalwert verglichen. Verwenden Sie Zeitpunkt Comparison-Funktionen. Fehlen geeignete Indizes kann auch Ausführung verlangsamen. Verwenden einer/objektrelationale Zuordnung Framework verstehen Sie wie es funktioniert und wie es die Datenzugriffsschicht Leistung auswirkt. Weitere Informationen finden Sie unter [Optimieren von Abfragen](https://technet.microsoft.com/library/ms176005.aspx).
- **Sie heben Normalisieren von Daten**. Datennormalisierung kann Inkonsistenzen vermeiden. Jedoch Overhead mehrere Indizes verwalten für die referenzielle Integrität überprüft, mehrere Zugriffe auf kleine Datenmengen durchführen und Verknüpfen von Tabellen zum Zusammenstellen der Daten ein, die die Leistung beeinträchtigen kann. Sollten Sie einige zusätzliche Speicher-Volume und Duplizierung geht um Datenspeicher entlasten. Bedenken Sie auch, wenn die Anwendung selbst (die normalerweise einfacher skalieren) herangezogen werden kann, Aufgaben wie die Verwaltung von referenziellen Integrität um Datenspeicher entlasten. Weitere Informationen finden Sie unter [partitioning Guidance Daten](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md).

## <a name="service-implementation"></a>Service-Implementierung
- **Asynchrone Aufrufe verwendet**. Verwenden Sie asynchronen Code bei Zugriff auf Ressourcen oder Dienste, die e/a-Bandbreite oder, begrenzt werden bemerkbar Latenz, um den aufrufenden Thread sperren. Verwenden Sie zum Implementieren von asynchroner Vorgängen [Aufgabenbasierte asynchronen Muster (TAP)](https://msdn.microsoft.com/library/hh873175.aspx).
- **Sperren Sie die Ressourcen und stattdessen optimistisch**. Niemals verweigert den Zugriff auf Ressourcen wie Speicher oder andere Dienste mit deutlichen Latenz ist dies eine primäre Ursache der Leistungseinbußen. Verwenden Sie immer optimistische Ansätze zum Verwalten der gleichzeitige Vorgänge wie Speicher schreiben. Mithilfe von der Speicherschicht auf Konflikte verwalten. In verteilten Anwendung können Daten nur schließlich übereinstimmen.
- **Wartezeiten, Netzwerke mit niedriger Bandbreite stark verdichteten Daten komprimieren**. In den meisten Fällen eine Anwendung ist die größte Datenmenge von der Anwendung generierte und über das Netzwerk HTTP-Antworten auf Clientanforderungen. HTTP-Komprimierung kann dies besonders für statischen Inhalt erheblich reduzieren. Dies reduziert Kosten als auch die Last auf dem Netzwerk jedoch dynamischen Inhalt komprimieren eine geringfügig höhere Last auf dem Server gilt. Andere allgemeine Umgebung Datenkompression kann übertragene Datenmenge reduzieren und Übertragung Zeit- und Kostenaufwand minimieren; komprimieren und Dekomprimieren Prozesse entstehen overhead Komprimierung sollte daher nur verwendet werden, wird ein nachweisbarer Performance-Gewinn. Andere Serialisierungsmethoden JSON oder binäre Codierung verringern die Nutzlastgröße und weniger auf die Leistung XML erhöhen wahrscheinlich ist.
- **Minimieren Sie die Zeit, die Verbindungen und Ressourcen verwendet werden**. Verwalten Sie Verbindungen und Ressourcen nur für als verwenden müssen. Beispielsweise so spät wie möglich öffnen Sie Verbindungen und lassen Sie so bald wie möglich an den Verbindungspool zurückgegeben werden. Erhalten Sie Ressourcen so spät wie möglich, und entsorgen Sie sie so bald wie möglich.
- **Minimieren Sie die Anzahl der Verbindungen erforderlich**. Verbindungen absorbieren Ressourcen. Die Anzahl, die erforderlich und sicherzustellen, dass die vorhandene Verbindungen möglichst wiederverwendet werden. Nach Durchführen der Authentifizierung, z. B. Identitätswechsel gegebenenfalls Code unter einer bestimmten Identität ausführen. Dies hilft den Verbindungspool Nutzen von Verbindungen wiederverwenden.

    > [AZURE.NOTE]: APIs for some services automatically reuse connections, provided service-specific guidelines are followed. It's important that you understand the conditions that enable connection reuse for each service that your application uses.

- **Anfragen in Batches Netzwerk optimieren**. Senden und Lesen von Nachrichten im Stapel beim Zugriff auf eine Warteschlange und beim Zugriff auf Speicher und Cache mehrere Lese- bzw. Schreibvorgänge als Batch ausgeführt. Dadurch können Effizienz und Speicher durch Verringerung der Anzahl der Aufrufe im Netzwerk.
- **Anforderung für serverseitige Sitzungszustands** möglichst. Verwaltung des serverseitigen Sitzungsstatus erfordert normalerweise Clientzugehörigkeit (, die jede Anforderung die gleiche Instanz routing ist) betrifft die Fähigkeit des Systems skaliert. Im Idealfall sollten Sie Kunden statusfreie in Bezug auf den Server, mit dem sie entwerfen. Die Anwendung muss Sitzungszustand beibehalten, vertrauliche Daten speichern oder Datenmengen pro Client in einer verteilten serverseitige zwischenspeichern, können alle Instanzen der Anwendung zugreifen.
- **Storage Tabellenschemas optimieren**. Wenn die Tabelle speichert die Tabellen- und Spaltennamen Namen übergeben und verarbeitet jede Abfrage wie Azure-Tabellenspeicher, müssen berücksichtigen Sie mit kürzeren Namen um diesen Aufwand zu verringern. Opfern Sie jedoch nicht Lesbarkeit und Verwaltung zu compact Namen.
- **Mit der Task Parallel Library (TPL) für asynchrone Operationen**. Die TPL vereinfacht die asynchronen Code schreiben, der e/a-Operationen. Verwenden Sie möglichst die Abhängigkeit eine Fortsetzung auf einen bestimmten Synchronisierungskontext zu _ConfigureAwait(false)_ . Dies reduziert die Wahrscheinlichkeit von Thread-Deadlocks.
- **Create Resource Dependencies während der Bereitstellung oder beim Start der Anwendung**. Vermeiden Sie wiederholte Aufrufe von Methoden, die eine Ressource zu testen und die Ressource dann erstellen, wenn er nicht vorhanden ist. (Wie _CloudTable.CreateIfNotExists_ und _CloudQueue.CreateIfNotExists_ in der Azure-Speicher-Clientbibliothek folgen diesem Muster). Diese Methoden können beträchtlichen Aufwand vorsehen, wenn sie vor jeder Zugriff auf eine Speichertabelle oder Speicherwarteschlange aufgerufen werden. Stattdessen:
 - Die erforderlichen Ressourcen erstellen, wenn die Anwendung bereitgestellt wird oder beim ersten Start (ein einzelner Aufruf an _CreateIfNotExists_ für jede Ressource den Startcode für eine Web- oder Arbeitskraft ist zulässig). Allerdings müssen Sie Ausnahmen behandeln, die auftreten können, wenn Ihr Code versucht, auf eine Ressource zuzugreifen, die nicht vorhanden ist. In diesen Situationen sollte die Ausnahme protokollieren und möglicherweise einem Operator informiert wird, dass eine Ressource fehlt.
 - Unter Umständen kann es angebracht, die fehlende Ressource als Teil der Ausnahmebehandlungscode erstellen sein. Aber Sie sollten dabei vorsichtig das Nichtvorhandensein der Ressource auf einen Programmierfehler (z. B. einen falsch geschriebene Ressourcennamen) oder anderen Infrastrukturebene Problem ist.
- **Einfache Frameworks verwenden**. Wählen Sie sorgfältig die APIs und Frameworks Ressourcenverwendung, Ausführungszeit und Gesamtlast auf die Anwendung zu verwenden. Z. B. Anwendung reduzieren und die Ausführung beschleunigen kann Service-Anfragen mit Web-API jedoch möglicherweise nicht für erweiterte Szenarien, in denen die zusätzlichen Funktionen der Windows Communication Foundation erforderlich sind.
- **Minimieren der Anzahl der Dienstkonten betrachten**. Z. B. ein spezielles Konto für den Zugriff auf Ressourcen oder Dienste, die beschränken auf Verbindungen bzw. Führen Sie, besser, weniger Verbindungen verwaltet werden. Dieser Ansatz ist für Dienste wie Datenbanken beeinflussen können aufgrund der Identitätswechsel des ursprünglichen Benutzers genau überwachen.
- **Führen Sie Performance profiling und Auslastungstests** während der Entwicklung, Test-Routinen und endgültige Version um sicherzustellen, dass die Anwendung führt und Skalierung nach Bedarf Diese Tests sollten auf dieselbe Art von Hardware als der Plattform und mit den gleichen Datentypen durchgeführt und Mengen und Laden es in der Produktion auftreten. Weitere Informationen finden Sie unter [Testen der Leistung eines Cloud-Diensts](vs-azure-tools-performance-profiling-cloud-services.md).
